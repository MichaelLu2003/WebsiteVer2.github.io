<!DOCTYPE html>
<html lang="en">
<head>
    <link rel="stylesheet" href="style.css">
    <title>Learning Model Editing - Research Projects</title>
</head>
<body>
    <nav>
        <ul>
            <li class="nav-logo"><img src="BAIR.png" alt="Logo"></li>
            <div class="nav-links">
                <li><a href="index.html">Home</a></li>
                <li><a href="team.html">Team</a></li>
                <li><a href="learn_model_editing.html">Learning Model Editing</a></li>
            </div>
        </ul>
        <div class="title-separator"></div>
    </nav>
    <div class="container">

        <section>
            <h2>Learning Model Editing</h2>
            <!-- Your content for Learning Model Editing here -->

            <div class="papers-list">
                <h3>BASIC METHODS FOR MODEL EDITING</h3>
                <ul>
                    <li><a href="#">Transformer Feed-Forward Layers Are Key-Value Memories</a></li>
                    <li><a href="#">Editing Factual Knowledge in Language Models</a></li>
                    <li><a href="#">Knowledge Neurons in Pretrained Transformers</a></li>
                    <li><a href="#">MEND - Fast Model Editing at Scale</a></li>
                    <li><a href="#">Do Language Models Have Beliefs? Methods for Detecting, Updating, and Visualizing Model Beliefs</a></li>
                    <li><a href="#">ROME - Locating and Editing Factual Associations in GPT</a></li>
                    <li><a href="#">SERAC - Memory-Based Model Editing at Scale</a></li>
                    <li><a href="#">MEMIT - Mass-Editing Memory in a Transformer</a></li>
                </ul>
                <h3>BASIC ANALYSIS PAPERS FOR MODEL EDITING</h3>
                <ul>
                    <li><a href="#">Does Localization Inform Editing?</a></li>
                    <li><a href="#">Editing Large Language Models: Problems, Methods, and Opportunities</a></li>
                    <li><a href="#">MQuAKE: Assessing Knowledge Editing in Language Models via Multi-Hop Questions</a></li>
                    <li><a href="#">Detecting Edit Failures In Large Language Models: An Improved Specificity Benchmark</a></li>
                    <li><a href="#">Evaluating the Ripple Effects of Knowledge Editing in Language Models</a></li>
                    <li><a href="#">Unveiling the Pitfalls of Knowledge Editing for Large Language Models</a></li>
                    <li><a href="#">Model Editing at Scale leads to Gradual and Catastrophic Forgetting</a></li>
                </ul>
            </div>
        </section>
    </div>
    <footer>
        <p>&copy; 2024 UC Berkeley. All rights reserved.</p>
    </footer>
</body>
</html>
